<center> <span style='font-size:2.5em;'>Project-3.EDA_&_ML: Hotel Review Score</span> <center>

# Какой кейс решаем?
<span style='font-size:1.2em;'>*Представим, что получили заказ от крупного американского банка. Он хранит огромный объём данных о клиентах, используемый в маркетинговых кампаниях. <br> <br>
Нам предоставили данные о проведении прошлой рекламной компании, направленной для привлечения клиентов для открытия депозита, с использованием прямого маркетинга (т.е. банк напрямую связывался с клиентом с помощью различных каналов связи). Такой метод сам по себе довольно затратный по времени, ресурсам и финансам, поэтому заказчику хотелось бы уметь выбирать среди своих клиентов именно тех, которые с наибольшей вероятностью воспользуются тем или иным предложением, и связываться именно с ними.* <br><br><br><br>
<span style='font-size:18px'>**Бизнес-задача:** </span>определить характеристики, по которым можно выявить клиентов, более склонных к открытию депозита в банке, и за счёт этого повысить результативность маркетинговой кампании.
<br><br>
<span style='font-size:18px'>**Техническая задача:**</span> построить модель машинного обучения, которая на основе предложенных характеристик клиента будет предсказывать, воспользуется он предложением об открытии депозита или нет.
</span>

# Задачи проекта
<span style='font-size:1.2em;'>

* Обработать исходные данные от пропусков, выбросов и дубликатов.

* Визуализировать данные.

* Исследовать данные, найти закономерности.

* Проверить признаки на мультиколлинеарность, удалить сильно зависимые признаки для повышения точности модели.

* Разделить данные на тестовую и тренировочную выборки.

* Отобрать самые информативные признаки.

* Нормализовать/стандартизировать данные.

* Создать и обучить несколько моделей для предсказания открытия депозита клиентом. 

* Сделать подбор гиперпараметров.

* Представить финальную модель.
</span>
# Используемые библиотеки
Version of Python - 3.12.2
* Pandas (2.2.1)
* Numpy (1.26.4)
* Seaborn (0.13.2)
* Matplotlib (3.8.4)
* Scikit-learn (1.5.0)
* Plotly (5.21.0)
* Optuna (3.6.1)

# Ссылка на датафрейм
Google Drive: https://drive.google.com/drive/folders/1Evh71mC9e1rzakzTpoqrglokdkjYo_hg?usp=sharing
# Признаки в исходном датафрейме
<span style='font-size:18px'>Данные о клиентах банка:</span>

age (возраст); <br><br>
job (сфера занятости); <br><br>
marital (семейное положение); <br><br>
education (уровень образования); <br><br>
default (имеется ли просроченный кредит); <br><br>
housing (имеется ли кредит на жильё); <br><br>
loan (имеется ли кредит на личные нужды); <br><br>
balance (баланс). <br><br><br>
<span style='font-size:18px'>Данные, связанные с последним контактом в контексте текущей маркетинговой кампании:</span>

contact (тип контакта с клиентом); <br><br>
month (месяц, в котором был последний контакт); <br><br>
day (день, в который был последний контакт); <br><br>
duration (продолжительность контакта в секундах). <br><br><br>
<span style='font-size:18px'>Прочие признаки:</span>

campaign (количество контактов с этим клиентом в течение текущей кампании); <br><br>
pdays (количество пропущенных дней с момента последней маркетинговой кампании до контакта в текущей кампании); <br><br>
previous (количество контактов до текущей кампании); <br><br>
poutcome (результат прошлой маркетинговой кампании) <br><br>
**deposit — согласился ли клиент открыть депозит** - *ключевой признак*
# Описание проекта
<span style='font-size:1.2em;'>Часть 1. Знакомство с данными, обработка пропусков и выбросов: </span>
<br>
* Все библиотеки, пакеты и данные успешно загружены.
* Проведён анализ типов данных, дубликатов не обнаружено.
* Найдены немногочисленные пропуски в признаке 'balance', были заполнены медианным значением.
* Найдены "скрытые" пропуски, они заменены на модальные значения.
* С помощью метода Тьюки найдены и удалены выбросы в признаке 'balance'.
<br><br>
<span style='font-size:1.2em;'>Часть 2. Разведывательный анализ (EDA)</span>
<br>
* Исследован баланс целевого признака.
* Построены графики зависимости числовых признаков друг от друга.
* Исследовано распределение признаков.
* Изучены значения и соотношения уникальных значений категориальных признаков.
* Категориальные признаки рассмотрены в разрезе целевого признака deposit.
<br><br>
<span style='font-size:1.2em;'>Часть 3. Преобразование данных</span>
<br><br>
* Произведена кодировка категориальных порядковых признаков с помощью LabelEncoder.
* Произведена бинаризация переменных, принимающих только бинарные значения: 'yes' (1) или 'no' (0).
* Наглядно рассмотрена мультикоррелиарность.
* Подготовлены данные для модели машинного обучения: датафрейм разделён на признаки и целевую перменную, которые в свою очередь были разелены стратифицированным (равномерным) разбиением на тренировочную и тестовую выборки.
* С помощью метода SelectKBest выбраны 15 наиболее информативных (скоррелированных с целевой переменной) признаков.
* Проведена нормализация данных благодаря MinMaxScaler().
<br><br>
<span style='font-size:1.2em;'>Часть 4. Решение задачи классификации: логистическая регрессия и решающие деревья</span>
<br><br>
* Как и полагается, сначала построены самые базовые модели: логистическая регрессия и дерево решений.
* Для дерева решений сделан подбор гиперпараметров с помощью метода GridSearchCV().
<br><br>
<span style='font-size:1.2em;'>Часть 5. Решение задачи классификации: ансамбли моделей и построение прогноза</span>
<br><br>
* Протестированы ансамблиевые модели: бутстрап, или случайный лес (RandomForestClassifier),
градиентный бустинг (GradientBoostingClassifier) и стэкинг (StackingClassifier())
* Для модели, показавшей себя лучше всех, - случайного леса - проведён подбор гиперпараметров с помощью мощной библиотеки Optuna.
<br><br>
<span style='font-size:1.2em;'>Финальная модель</span>
<br><br>
* Проведён подбор порога вероятности для задачи классификации.
* Составлен лучший алгоритм решения данной задачи.
<br><br>
# Итоги работы
На выходе получили готовую модель машинного обучения, которая предсказывает оценку отеля с точностью примерно 83 %. <br>
f1-метрика: 0.83

Был проведён тщательный анализ данных и их визуализация, исходные данные преобразованы в более понятный для модели вид, сделан отбор признаков, все признаки нормализованы, подобраны гиперпараметры и оптимальный порог вероятности.